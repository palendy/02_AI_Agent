# AI Agent Chatbot v2.2

GitHub ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì§€ëŠ¥í˜• ì±—ë´‡ ì‹œìŠ¤í…œìœ¼ë¡œ, Corrective RAG, LangGraph ì›Œí¬í”Œë¡œìš°, Hybrid Search, Cross-Encoder Re-rankingì„ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### 1. **Corrective RAG (Corrective Retrieval-Augmented Generation)**
- **ìë™ ì¬ì‹œë„**: ê´€ë ¨ì„± ë¶€ì¡± ì‹œ ì¿¼ë¦¬ ì¬ì‘ì„± ë° ì¬ê²€ìƒ‰
- **ë‹¤ì¤‘ ê²€ìƒ‰ ì†ŒìŠ¤**: ë²¡í„° ìŠ¤í† ì–´ â†’ ì±„íŒ… íˆìŠ¤í† ë¦¬ â†’ GitHub Issue ê²€ìƒ‰
- **ê´€ë ¨ì„± í‰ê°€**: 0.6 ì´ìƒì˜ ì„ê³„ê°’ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ ë³´ì¥
- **ì˜¤íƒ€ ë³´ì •**: ì§ˆë¬¸ rewrite ì‹œ ìë™ ì˜¤íƒ€ ìˆ˜ì •

### 2. **LangGraph ì›Œí¬í”Œë¡œìš°**
- **ìƒíƒœ ê¸°ë°˜ ê´€ë¦¬**: ë³µì¡í•œ AI ì—ì´ì „íŠ¸ ë¡œì§ì„ ê·¸ë˜í”„ë¡œ ê´€ë¦¬
- **ì¡°ê±´ë¶€ ë¶„ê¸°**: ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¥¸ ìë™ ê²½ë¡œ ì„ íƒ
- **ì—ëŸ¬ ì²˜ë¦¬**: í†µí•©ëœ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

### 3. **Hybrid Search + Cross-Encoder Re-ranking**
- **BM25 ìŠ¤ì½”ì–´ë§**: í‚¤ì›Œë“œ ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­ (60% ê°€ì¤‘ì¹˜)
- **Dense Embedding**: OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•œ ì˜ë¯¸ì  ìœ ì‚¬ë„ (40% ê°€ì¤‘ì¹˜)
- **Cross-Encoder Re-ranking**: ìµœì¢… ìˆœìœ„ ê²°ì •ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
- **GitHub Issue ê²€ìƒ‰**: ìœ ì‚¬í•œ ì´ìŠˆ ìë™ ê²€ìƒ‰ ë° ë‹µë³€ ì œê³µ

### 4. **ì‚¬ìš©ì í”¼ë“œë°± ì‹œìŠ¤í…œ**
- **ë§Œì¡±ë„ í‰ê°€**: ğŸ‘ ë§Œì¡± / ğŸ‘ ë¶ˆë§Œì¡± ë²„íŠ¼
- **ìë™ ì €ì¥**: ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ìë™ ì €ì¥
- **í’ˆì§ˆ ê¸°ì¤€**: ë‹µë³€ í’ˆì§ˆ ì ìˆ˜ 0.5 ì´ìƒì¼ ë•Œë§Œ ì €ì¥
- **ì¬ì‚¬ìš©**: í–¥í›„ ìœ ì‚¬í•œ ì§ˆë¬¸ì— ì €ì¥ëœ ë‹µë³€ ì¬ì‚¬ìš©

### 5. **ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬**
- **ìœ ì‚¬ë„ ê²€ìƒ‰**: ê³¼ê±° ëŒ€í™”ì—ì„œ ê´€ë ¨ ì§ˆë¬¸ ìë™ ê²€ìƒ‰
- **ì„ê³„ê°’ ì¡°ì •**: ìœ ì‚¬ë„ 0.5 ì´ìƒì—ì„œ ë§¤ì¹­
- **ì„¸ì…˜ ê´€ë¦¬**: ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ë¶„ë¦¬ ë° ê´€ë¦¬
- **í†µê³„ ì œê³µ**: ì±„íŒ… íˆìŠ¤í† ë¦¬ í†µê³„ ë° ë¶„ì„

### 6. **GitHub í†µí•©**
- **ìë™ ì´ìŠˆ ì œì•ˆ**: ë‹µë³€ ì‹¤íŒ¨ ì‹œ GitHub Issue ìƒì„± ì œì•ˆ
- **ì´ìŠˆ ê²€ìƒ‰**: ìœ ì‚¬í•œ GitHub Issue ìë™ ê²€ìƒ‰
- **ë‹µë³€ ì¶”ì¶œ**: Closed ì´ìŠˆì—ì„œ í•´ê²° ë°©ë²• ì¶”ì¶œ
- **URL ìƒì„±**: ìë™ìœ¼ë¡œ GitHub Issue ìƒì„± URL ì œê³µ

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    A[ì‚¬ìš©ì ì§ˆë¬¸] --> B[LangGraph ì›Œí¬í”Œë¡œìš°]
    B --> C[ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰]
    C --> D[ê´€ë ¨ì„± í‰ê°€]
    D -->|í†µê³¼| E[ë‹µë³€ ìƒì„±]
    D -->|ì‹¤íŒ¨| F[ì±„íŒ… íˆìŠ¤í† ë¦¬ ê²€ìƒ‰]
    F -->|ë°œê²¬| G[ì €ì¥ëœ ë‹µë³€ ë°˜í™˜]
    F -->|ì—†ìŒ| H[GitHub Issue ê²€ìƒ‰]
    H --> I[Hybrid Search + Re-ranking]
    I --> J[ì´ìŠˆ ê¸°ë°˜ ë‹µë³€]
    E --> K[ì‚¬ìš©ì í”¼ë“œë°±]
    G --> K
    J --> K
    K -->|ë§Œì¡±| L[ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥]
    K -->|ë¶ˆë§Œì¡±| M[ì €ì¥í•˜ì§€ ì•ŠìŒ]
```

## ğŸ” í•µì‹¬ ì½”ë“œ êµ¬ì¡°

### 1. **LangGraph ì›Œí¬í”Œë¡œìš° ë…¸ë“œ**

```python
# model/langgraph_workflow.py
class CorrectiveRAGWorkflow:
    def __init__(self, vector_store, chat_history_manager, model_name):
        self.vector_store = vector_store
        self.chat_history_manager = chat_history_manager
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self._build_workflow()
    
    def _build_workflow(self):
        """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±"""
        workflow = StateGraph(CorrectiveRAGState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("retrieve", self._retrieve_node)
        workflow.add_node("grade", self._grade_node)
        workflow.add_node("generate", self._generate_node)
        workflow.add_node("rewrite", self._rewrite_node)
        workflow.add_node("history_search", self._history_search_node)
        workflow.add_node("issue_search", self._issue_search_node)
        workflow.add_node("final_answer", self._final_answer_node)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.add_edge("retrieve", "grade")
        workflow.add_conditional_edges("grade", self._should_continue)
        workflow.add_edge("rewrite", "retrieve")
        workflow.add_edge("generate", "final_answer")
        workflow.add_edge("history_search", "grade")
        workflow.add_edge("issue_search", "final_answer")
        
        self.workflow = workflow.compile()
```

### 2. **Hybrid Search êµ¬í˜„**

```python
# model/github_issue_helper.py
class GitHubIssueHelper:
    def search_similar_issues(self, question: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """Hybrid Search + Cross-Encoder Re-ranking"""
        try:
            # 1. í›„ë³´ ì´ìŠˆ ìˆ˜ì§‘
            candidate_issues = self._get_candidate_issues(question)
            
            # 2. Hybrid Score ê³„ì‚°
            hybrid_scores = self._calculate_hybrid_scores(question, candidate_issues)
            
            # 3. Cross-Encoder Re-ranking
            reranked_issues = self._cross_encoder_rerank(question, hybrid_scores, max_results)
            
            return reranked_issues
        except Exception as e:
            logger.error(f"GitHub Issue ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_hybrid_scores(self, question: str, issues: List[Dict]) -> List[Dict]:
        """BM25 + Dense Embedding Hybrid Score"""
        question_embedding = self.embedding_model.embed_query(question)
        
        for issue in issues:
            # BM25 Score (60%)
            bm25_score = self._calculate_bm25_score(question, issue['text'])
            
            # Dense Score (40%)
            dense_score = self._calculate_dense_score(question_embedding, issue['embedding'])
            
            # Hybrid Score
            issue['hybrid_score'] = bm25_score * 0.6 + dense_score * 0.4
        
        return sorted(issues, key=lambda x: x['hybrid_score'], reverse=True)
```

### 3. **ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬**

```python
# model/chat_history.py
class ChatHistoryManager:
    def search_similar_questions(self, question: str, k: int = 5) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰"""
        try:
            # ì§ˆë¬¸ ì„ë² ë”©
            question_embedding = self.embedding_model.embed_query(question)
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[question_embedding],
                n_results=k,
                include=['metadatas', 'documents', 'distances']
            )
            
            similar_questions = []
            for i, (metadata, document, distance) in enumerate(zip(
                results['metadatas'][0], 
                results['documents'][0], 
                results['distances'][0]
            )):
                similarity_score = 1 - distance
                if similarity_score >= 0.5:  # ì„ê³„ê°’ 0.5
                    similar_questions.append({
                        'question': metadata['question'],
                        'answer': document,
                        'similarity_score': similarity_score,
                        'session_id': metadata['session_id']
                    })
            
            return similar_questions
        except Exception as e:
            logger.error(f"ì±„íŒ… íˆìŠ¤í† ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
```

### 4. **Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤**

```python
# view/app.py
def render_chat_interface():
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì±—ë´‡ ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            response = st.session_state.chatbot.generate_response(
                prompt, 
                st.session_state.current_session_id
            )
        
        # ì‘ë‹µ í‘œì‹œ
        with st.chat_message("assistant"):
            st.markdown(response['answer'])
            
            # í”¼ë“œë°± ë²„íŠ¼
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ‘ ë§Œì¡±", key="satisfied"):
                    handle_feedback("satisfied", response)
            with col2:
                if st.button("ğŸ‘ ë¶ˆë§Œì¡±", key="dissatisfied"):
                    handle_feedback("dissatisfied", response)
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. **í™˜ê²½ ì„¤ì •**
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/palendy/02_AI_Agent.git
cd 02_AI_Agent/02_chatbot_agent

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**
```bash
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your_openai_api_key
GITHUB_TOKEN=your_github_token
DEFAULT_MODEL_NAME=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-large
RELEVANCE_THRESHOLD=0.6
GITHUB_REPOSITORIES=https://github.com/owner/repo1,https://github.com/owner/repo2
LOG_LEVEL=INFO

# ChromaDB ì„¤ì •
CHROMA_MAX_SIZE=0
CHAT_HISTORY_MAX_SIZE=2147483648
```

### 3. **ì‹¤í–‰**
```bash
# Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤
streamlit run view/app.py

# CLI ì¸í„°í˜ì´ìŠ¤
python main.py
```

## ğŸ”„ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¡°

### ì „ì²´ ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

#### ì‹¤ì œ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¡° (ìë™ ìƒì„±)

```mermaid
---
config:
  flowchart:
    curve: linear
---
graph TD;
	__start__([<p>__start__</p>]):::first
	retrieve(retrieve)
	grade(grade)
	generate(generate)
	rewrite(rewrite)
	history_search(history_search)
	issue_search(issue_search)
	final_answer(final_answer)
	__end__([<p>__end__</p>]):::last
	__start__ --> retrieve;
	grade -.-> final_answer;
	grade -.-> generate;
	grade -.-> history_search;
	grade -.-> issue_search;
	grade -.-> rewrite;
	history_search --> grade;
	issue_search --> final_answer;
	retrieve --> grade;
	rewrite --> retrieve;
	final_answer --> __end__;
	generate --> __end__;
	classDef default fill:#f2f0ff,line-height:1.2
	classDef first fill-opacity:0
	classDef last fill:#bfb6fc
```

#### ì›Œí¬í”Œë¡œìš° íë¦„ ì„¤ëª…

```mermaid
graph TD
    Start([ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥]) --> Retrieve[ğŸ” retrieve: ë¬¸ì„œ ê²€ìƒ‰]
    Retrieve --> Grade[ğŸ“Š grade: ê´€ë ¨ì„± í‰ê°€]
    
    Grade -->|ê´€ë ¨ì„± í†µê³¼| Generate[ğŸ¤– generate: ë‹µë³€ ìƒì„±]
    Grade -->|ê´€ë ¨ì„± ë¶€ì¡±| Decision{ğŸ¤” ì¬ì‹œë„ ê²°ì •}
    
    Decision -->|retry_count < max_retries| Rewrite[âœï¸ rewrite: ì¿¼ë¦¬ ì¬ì‘ì„±]
    Decision -->|retry_count >= max_retries| HistorySearch[ğŸ“š history_search: ì±„íŒ… íˆìŠ¤í† ë¦¬ ê²€ìƒ‰]
    
    Rewrite --> Retrieve
    
    HistorySearch --> Grade2[ğŸ“Š grade: ê´€ë ¨ì„± ì¬í‰ê°€]
    Grade2 -->|ê´€ë ¨ì„± í†µê³¼| IssueSearch[ğŸ” issue_search: GitHub Issue ê²€ìƒ‰]
    Grade2 -->|ê´€ë ¨ì„± ë¶€ì¡±| IssueSearch
    
    IssueSearch --> FinalAnswer[ğŸ final_answer: ìµœì¢… ë‹µë³€]
    Generate --> End([âœ… ë‹µë³€ ì™„ë£Œ])
    FinalAnswer --> End
    
    classDef startEnd fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef process fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#e65100,stroke-width:2px
    
    class Start,End startEnd
    class Retrieve,Grade,Generate,Rewrite,HistorySearch,IssueSearch,FinalAnswer process
    class Decision,Grade2 decision
```

### ì›Œí¬í”Œë¡œìš° ë…¸ë“œ ì„¤ëª…

| ë…¸ë“œ | ì„¤ëª… | ì…ë ¥ | ì¶œë ¥ |
|------|------|------|------|
| **retrieve** | ë¬¸ì„œ ê²€ìƒ‰ | ì‚¬ìš©ì ì§ˆë¬¸ | ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡ |
| **grade** | ê´€ë ¨ì„± í‰ê°€ | ì§ˆë¬¸ + ë¬¸ì„œ | ê´€ë ¨ì„± ì ìˆ˜ + í†µê³¼/ì‹¤íŒ¨ |
| **generate** | ë‹µë³€ ìƒì„± | ì§ˆë¬¸ + ê´€ë ¨ ë¬¸ì„œ | ìµœì¢… ë‹µë³€ |
| **rewrite** | ì¿¼ë¦¬ ì¬ì‘ì„± | ì›ë³¸ ì§ˆë¬¸ + ì‹¤íŒ¨ ì´ìœ  | ê°œì„ ëœ ê²€ìƒ‰ ì¿¼ë¦¬ |
| **history_search** | ì±„íŒ… íˆìŠ¤í† ë¦¬ ê²€ìƒ‰ | ì§ˆë¬¸ | ìœ ì‚¬í•œ ê³¼ê±° ëŒ€í™” |
| **issue_search** | GitHub Issue ê²€ìƒ‰ | ì§ˆë¬¸ | ê´€ë ¨ GitHub ì´ìŠˆ |
| **final_answer** | ìµœì¢… ë‹µë³€ ìƒì„± | ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ | í†µí•©ëœ ìµœì¢… ë‹µë³€ |

### ì˜ì‚¬ê²°ì • ë¡œì§

```python
def _should_retry(state):
    retry_count = state.get("retry_count", 0)
    docs_are_relevant = state.get("docs_are_relevant", False)
    relevance_score = state.get("relevance_score", 0.0)
    search_source = state.get("search_source", "unknown")
    
    # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬
    if retry_count >= max_retries:
        return "final_answer"
    
    # ê´€ë ¨ì„± ë¶€ì¡± ì‹œ ì¬ì‹œë„
    if not docs_are_relevant:
        if search_source == "db" and retry_count >= 1:
            return "history_search"
        elif search_source == "history":
            return "issue_search"
        else:
            return "rewrite"
    
    # ê´€ë ¨ì„± í†µê³¼ ì‹œ ë‹µë³€ ìƒì„±
    return "generate"
```

## ğŸ”§ ì£¼ìš” ì„¤ì •

### 1. **ê²€ìƒ‰ ì„¤ì •**
```python
# config.py
RELEVANCE_THRESHOLD = 0.6      # ê´€ë ¨ì„± ì„ê³„ê°’
MAX_RETRIES = 3                # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
MAX_SEARCH_RESULTS = 8         # ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
CHUNK_SIZE = 1500              # ë¬¸ì„œ ì²­í¬ í¬ê¸°
CHUNK_OVERLAP = 300            # ì²­í¬ ì˜¤ë²„ë©
```

### 2. **ëª¨ë¸ ì„¤ì •**
```python
DEFAULT_MODEL_NAME = "gpt-4o-mini"           # ê¸°ë³¸ LLM
EMBEDDING_MODEL = "text-embedding-3-large"   # ì„ë² ë”© ëª¨ë¸
CROSS_ENCODER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"  # Re-ranking
```

### 3. **ChromaDB ì„¤ì •**
```python
CHROMA_MAX_SIZE = 0  # ë¬¸ì„œ ì €ì¥ìš© ìµœëŒ€ í¬ê¸° (0=ì œí•œ ì—†ìŒ)
CHAT_HISTORY_MAX_SIZE = 2147483648  # ì±„íŒ… íˆìŠ¤í† ë¦¬ ìµœëŒ€ í¬ê¸° (2GB)
```

## ğŸ“ˆ ì‚¬ìš© ì˜ˆì‹œ

### 1. **ê¸°ë³¸ ì§ˆë¬¸**
```
ì‚¬ìš©ì: "SRS Agentì—ì„œ module not found ì—ëŸ¬ê°€ ë°œìƒí•´ìš”"
ì‹œìŠ¤í…œ: 
1. ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
2. ê´€ë ¨ì„± í‰ê°€ (0.8 > 0.6 í†µê³¼)
3. ë‹µë³€ ìƒì„± ë° ì œê³µ
4. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
```

### 2. **ìœ ì‚¬í•œ ì§ˆë¬¸ ì¬ì‚¬ìš©**
```
ì‚¬ìš©ì: "SRS Agentì—ì„œ module not foun ì—ëŸ¬ ë­ì•¼"  # ì˜¤íƒ€ í¬í•¨
ì‹œìŠ¤í…œ:
1. ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰ (ê´€ë ¨ì„± ë¶€ì¡±)
2. ì¿¼ë¦¬ ì¬ì‘ì„± ("module not found"ë¡œ ìˆ˜ì •)
3. ì±„íŒ… íˆìŠ¤í† ë¦¬ ê²€ìƒ‰ (ìœ ì‚¬ë„ 0.7 > 0.5)
4. ì´ì „ ë‹µë³€ ì¬ì‚¬ìš©
```

### 3. **GitHub Issue ê²€ìƒ‰**
```
ì‚¬ìš©ì: "ì„¤ì¹˜ ë°©ë²•ì„ ëª¨ë¥´ê² ì–´ìš”"
ì‹œìŠ¤í…œ:
1. ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰ (ê´€ë ¨ì„± ë¶€ì¡±)
2. ì±„íŒ… íˆìŠ¤í† ë¦¬ ê²€ìƒ‰ (ê²°ê³¼ ì—†ìŒ)
3. GitHub Issue ê²€ìƒ‰ (Hybrid Search + Re-ranking)
4. ìœ ì‚¬í•œ ì´ìŠˆ ë‹µë³€ ì œê³µ
5. GitHub Issue ìƒì„± ì œì•ˆ
```

## ğŸ¯ í•µì‹¬ ê°œì„ ì‚¬í•­

### v2.2 (í˜„ì¬)
- âœ… Hybrid Search + Cross-Encoder Re-ranking
- âœ… ì‚¬ìš©ì í”¼ë“œë°± ì‹œìŠ¤í…œ
- âœ… ìœ ì‚¬ë„ ê²€ìƒ‰ ì„ê³„ê°’ ìµœì í™” (0.8 â†’ 0.5)
- âœ… ì˜¤íƒ€ ìë™ ë³´ì •
- âœ… ì½”ë“œ ì •ë¦¬ ë° ìµœì í™”
- âœ… UI ê°œì„  (ì„œë¹„ìŠ¤ ì„ íƒ ë²„íŠ¼ ìµœì í™”)
- âœ… ìƒì„¸í•œ ë¡œê¹… ì‹œìŠ¤í…œ
- âœ… í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ë¡œê·¸ ë ˆë²¨ ì„¤ì •

### v2.1
- âœ… GitHub Issue ì œì•ˆ ì‹œìŠ¤í…œ
- âœ… ì›Œí¬í”Œë¡œìš° ë‹¨ìˆœí™”
- âœ… ì—ëŸ¬ ë…¸ë“œ ì œê±°

### v2.0
- âœ… LangGraph ì›Œí¬í”Œë¡œìš° ë„ì…
- âœ… ë‹¤ì¤‘ Repository ì§€ì›
- âœ… ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- âœ… ê´€ë ¨ì„± ì„ê³„ê°’ ì¡°ì •

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
02_chatbot_agent/
â”œâ”€â”€ model/                          # í•µì‹¬ ëª¨ë¸ êµ¬í˜„
â”‚   â”œâ”€â”€ langgraph_workflow.py      # LangGraph ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ rag_agent.py               # Corrective RAG Agent
â”‚   â”œâ”€â”€ github_issue_helper.py     # GitHub Issue ê²€ìƒ‰
â”‚   â”œâ”€â”€ chat_history.py            # ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
â”‚   â”œâ”€â”€ vector_store.py            # ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬
â”‚   â””â”€â”€ github_extractor.py        # GitHub ë¬¸ì„œ ì¶”ì¶œ
â”œâ”€â”€ view/                          # ì›¹ ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ app.py                     # ë©”ì¸ Streamlit ì•±
â”‚   â””â”€â”€ components/                # UI ì»´í¬ë„ŒíŠ¸
â”œâ”€â”€ config.py                      # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ main.py                        # CLI ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ run_streamlit.py              # Streamlit ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt               # ì˜ì¡´ì„± ëª©ë¡
â””â”€â”€ README.md                      # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```


## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.


---
