"""
GitHub Issue Helper
ì—ëŸ¬ ë°œìƒ ì‹œ GitHub Issue ë“±ë¡ì„ ë„ì™€ì£¼ëŠ” í´ë˜ìŠ¤
"""

import os
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import requests
from urllib.parse import quote
import re
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from collections import Counter
import math

from config import get_config
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GitHubIssueHelper:
    """GitHub Issue ë“±ë¡ì„ ë„ì™€ì£¼ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, repository_url: str = None):
        """
        GitHubIssueHelper ì´ˆê¸°í™”
        
        Args:
            repository_url: GitHub repository URL (ì˜ˆ: https://github.com/owner/repo)
        """
        self.config = get_config()
        self.repository_url = repository_url or self._get_default_repository()
        self.github_token = self.config.github_token
        
        # Repository ì •ë³´ íŒŒì‹±
        self.owner, self.repo = self._parse_repository_url()
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = OpenAIEmbeddings(
            openai_api_key=self.config.openai_api_key,
            model=self.config.embedding_model
        )
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™”
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        # ë¶ˆìš©ì–´ ëª©ë¡ (í•œêµ­ì–´ + ì˜ì–´)
        self.stop_words = {
            'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì˜', 'ì™€', 'ê³¼', 'ëŠ”', 'ì€', 'ë„', 'ë§Œ', 
            'ë¶€í„°', 'ê¹Œì§€', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ì²˜ëŸ¼', 'ê°™ì´', 'ë³´ë‹¤', 'ë§ˆë‹¤', 'ì¡°ì°¨', 'ë§ˆì €', 'ë¿',
            'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ì™œ', 'ëˆ„ê°€', 'ì–´ëŠ', 'ëª‡', 'ì–¼ë§ˆë‚˜',
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
            'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',
            'will', 'would', 'could', 'should', 'may', 'might', 'can', 'must', 'shall'
        }
    
    def _get_default_repository(self) -> str:
        """ê¸°ë³¸ repository URL ë°˜í™˜"""
        repositories = self.config.github_repositories
        if repositories:
            return repositories[0]
        return "https://github.com/your-username/your-repository"
    
    def _parse_repository_url(self) -> tuple:
        """Repository URLì—ì„œ ownerì™€ repo ì¶”ì¶œ"""
        try:
            if not self.repository_url:
                return "unknown", "unknown"
            
            # https://github.com/owner/repo í˜•íƒœì—ì„œ ownerì™€ repo ì¶”ì¶œ
            parts = self.repository_url.replace("https://github.com/", "").split("/")
            if len(parts) >= 2:
                return parts[0], parts[1].replace(".git", "")
            return "unknown", "unknown"
        except Exception as e:
            logger.error(f"Repository URL íŒŒì‹± ì‹¤íŒ¨: {e}")
            return "unknown", "unknown"
    
    def create_issue_url(self, 
                        title: str, 
                        body: str, 
                        labels: list = None) -> str:
        """
        GitHub Issue ìƒì„± URL ìƒì„±
        
        Args:
            title: Issue ì œëª©
            body: Issue ë‚´ìš©
            labels: ë¼ë²¨ ëª©ë¡
            
        Returns:
            str: GitHub Issue ìƒì„± URL
        """
        try:
            base_url = f"https://github.com/{self.owner}/{self.repo}/issues/new"
            
            # URL íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {
                'title': title,
                'body': body
            }
            
            if labels:
                params['labels'] = ','.join(labels)
            
            # URL ì¸ì½”ë”©
            query_string = '&'.join([f"{k}={quote(str(v))}" for k, v in params.items()])
            issue_url = f"{base_url}?{query_string}"
            
            logger.info(f"GitHub Issue URL ìƒì„±: {issue_url}")
            return issue_url
            
        except Exception as e:
            logger.error(f"GitHub Issue URL ìƒì„± ì‹¤íŒ¨: {e}")
            return f"https://github.com/{self.owner}/{self.repo}/issues/new"
    
    def create_issue_template(self, 
                            question: str, 
                            error_message: str = None,
                            system_info: Dict[str, Any] = None) -> Dict[str, str]:
        """
        GitHub Issue í…œí”Œë¦¿ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            error_message: ì—ëŸ¬ ë©”ì‹œì§€
            system_info: ì‹œìŠ¤í…œ ì •ë³´
            
        Returns:
            Dict[str, str]: Issue ì œëª©ê³¼ ë‚´ìš©
        """
        try:
            # Issue ì œëª© ìƒì„±
            title = f"ì§ˆë¬¸ ë‹µë³€ ì‹¤íŒ¨: {question[:50]}{'...' if len(question) > 50 else ''}"
            
            # Issue ë‚´ìš© ìƒì„±
            body = f"""## ğŸ› ì§ˆë¬¸ ë‹µë³€ ì‹¤íŒ¨ ë³´ê³ 

### ğŸ“ ì§ˆë¬¸ ë‚´ìš©
```
{question}
```

### âŒ ë°œìƒí•œ ë¬¸ì œ
"""
            
            if error_message:
                body += f"```\n{error_message}\n```\n\n"
            else:
                body += "ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
            
            # ì‹œìŠ¤í…œ ì •ë³´ ì¶”ê°€
            if system_info:
                body += f"""### ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´
- **ëª¨ë¸**: {system_info.get('model_name', 'Unknown')}
- **ì„ë² ë”© ëª¨ë¸**: {system_info.get('embedding_model', 'Unknown')}
- **ê´€ë ¨ì„± ì„ê³„ê°’**: {system_info.get('relevance_threshold', 'Unknown')}
- **ìµœëŒ€ ì¬ì‹œë„**: {system_info.get('max_retries', 'Unknown')}
- **ë¬¸ì„œ ìˆ˜**: {system_info.get('document_count', 'Unknown')}
- **ì±„íŒ… íˆìŠ¤í† ë¦¬ ìˆ˜**: {system_info.get('conversation_count', 'Unknown')}

"""
            
            # ì¶”ê°€ ì •ë³´
            body += f"""### ğŸ“… ë°œìƒ ì‹œê°„
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### ğŸ” ì¬í˜„ ë‹¨ê³„
1. ìœ„ì˜ ì§ˆë¬¸ì„ ì…ë ¥
2. ì‹œìŠ¤í…œì´ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í•¨

### ğŸ’¡ ì˜ˆìƒë˜ëŠ” ì›ì¸
- ê´€ë ¨ ë¬¸ì„œê°€ ë²¡í„° ìŠ¤í† ì–´ì— ì—†ìŒ
- ì§ˆë¬¸ì´ ë„ˆë¬´ êµ¬ì²´ì ì´ê±°ë‚˜ ëª¨í˜¸í•¨
- ì‹œìŠ¤í…œ ì„¤ì • ë¬¸ì œ
- API í˜¸ì¶œ ì˜¤ë¥˜

### ğŸ¯ ê°œì„  ì œì•ˆ
- [ ] ê´€ë ¨ ë¬¸ì„œ ì¶”ê°€ í•„ìš”
- [ ] ì§ˆë¬¸ ì¬êµ¬ì„± í•„ìš”
- [ ] ì‹œìŠ¤í…œ ì„¤ì • ì¡°ì • í•„ìš”
- [ ] ê¸°íƒ€: ___________

---
*ì´ IssueëŠ” AI Agent Chatbotì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
            
            return {
                'title': title,
                'body': body
            }
            
        except Exception as e:
            logger.error(f"Issue í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'title': f"ì§ˆë¬¸ ë‹µë³€ ì‹¤íŒ¨: {question[:50]}",
                'body': f"ì§ˆë¬¸: {question}\n\nì—ëŸ¬: {error_message or 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨'}"
            }
    
    def suggest_issue_creation(self, 
                              question: str, 
                              error_message: str = None,
                              system_info: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        GitHub Issue ìƒì„± ì œì•ˆ
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            error_message: ì—ëŸ¬ ë©”ì‹œì§€
            system_info: ì‹œìŠ¤í…œ ì •ë³´
            
        Returns:
            Dict[str, Any]: Issue ìƒì„± ì œì•ˆ ì •ë³´
        """
        try:
            # Issue í…œí”Œë¦¿ ìƒì„±
            template = self.create_issue_template(question, error_message, system_info)
            
            # Issue URL ìƒì„±
            issue_url = self.create_issue_url(
                title=template['title'],
                body=template['body'],
                labels=['bug', 'question-answer-failure', 'auto-generated']
            )
            
            return {
                'suggested': True,
                'title': template['title'],
                'body': template['body'],
                'url': issue_url,
                'repository': f"{self.owner}/{self.repo}",
                'message': f"ì§ˆë¬¸ì— ë‹µë³€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. GitHub Issueë¥¼ ìƒì„±í•˜ì—¬ ë¬¸ì œë¥¼ ë³´ê³ í•´ì£¼ì„¸ìš”."
            }
            
        except Exception as e:
            logger.error(f"Issue ìƒì„± ì œì•ˆ ì‹¤íŒ¨: {e}")
            return {
                'suggested': False,
                'message': f"Issue ìƒì„± ì œì•ˆ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    def search_similar_issues(self, question: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê¸°ë°˜ ìœ ì‚¬í•œ GitHub Issue ê²€ìƒ‰
        (BM25 + ì˜ë¯¸ì  ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­)
        
        Args:
            question: ê²€ìƒ‰í•  ì§ˆë¬¸
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict[str, Any]]: ìœ ì‚¬í•œ ì´ìŠˆ ëª©ë¡
        """
        try:
            if not self.github_token:
                logger.warning("GitHub í† í°ì´ ì—†ì–´ ì´ìŠˆ ê²€ìƒ‰ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ GitHub ì´ìŠˆ ê²€ìƒ‰ ì‹œì‘: {question}")
            
            # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ì´ˆê¸° ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ì´ìŠˆë“¤ ìˆ˜ì§‘
            candidate_issues = self._get_candidate_issues(question, max_results * 4)  # 4ë°° ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
            
            if not candidate_issues:
                logger.info("í›„ë³´ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # 2ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ (BM25 + ì˜ë¯¸ì  ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­)
            scored_issues = self._calculate_hybrid_similarity(question, candidate_issues)
            
            # 3ë‹¨ê³„: ìµœì¢… ìŠ¤ì½”ì–´ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ ê²°ê³¼ ë°˜í™˜
            scored_issues.sort(key=lambda x: x['final_score'], reverse=True)
            top_issues = scored_issues[:max_results]
            
            logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ì´ìŠˆ {len(top_issues)}ê°œ ë°œê²¬")
            return top_issues
                
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì´ìŠˆ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_candidate_issues(self, question: str, max_candidates: int = 15) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í›„ë³´ ì´ìŠˆë“¤ì„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            search_terms = self._extract_search_terms(question)
            query = " ".join(search_terms)
            
            # API ìš”ì²­ í—¤ë”
            headers = {
                'Authorization': f'token {self.github_token}',
                'Accept': 'application/vnd.github.v3+json',
                'User-Agent': 'AI-Agent-Chatbot'
            }
            
            # API íŒŒë¼ë¯¸í„°
            params = {
                'q': f"{query} repo:{self.owner}/{self.repo}",
                'sort': 'updated',
                'order': 'desc',
                'per_page': max_candidates,
                'state': 'all'
            }
            
            # GitHub Search API ì‚¬ìš©
            search_url = "https://api.github.com/search/issues"
            
            logger.info(f"í›„ë³´ ì´ìŠˆ ê²€ìƒ‰ ì¤‘: {query}")
            response = requests.get(search_url, headers=headers, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                issues = data.get('items', [])
                
                # ì´ìŠˆ ì •ë³´ ì •ë¦¬
                candidate_issues = []
                for issue in issues:
                    issue_info = {
                        'number': issue.get('number'),
                        'title': issue.get('title'),
                        'body': issue.get('body', ''),
                        'state': issue.get('state'),
                        'url': issue.get('html_url'),
                        'created_at': issue.get('created_at'),
                        'updated_at': issue.get('updated_at'),
                        'labels': [label.get('name') for label in issue.get('labels', [])]
                    }
                    candidate_issues.append(issue_info)
                
                logger.info(f"í›„ë³´ ì´ìŠˆ {len(candidate_issues)}ê°œ ìˆ˜ì§‘")
                return candidate_issues
                
            else:
                logger.error(f"GitHub API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            logger.error(f"í›„ë³´ ì´ìŠˆ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_hybrid_similarity(self, question: str, candidate_issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ (BM25 + ì˜ë¯¸ì  ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­)"""
        try:
            if not candidate_issues:
                return []
            
            # ì§ˆë¬¸ ì „ì²˜ë¦¬
            question_tokens = self._preprocess_text(question)
            
            # ê° ì´ìŠˆì— ëŒ€í•´ ì—¬ëŸ¬ ìŠ¤ì½”ì–´ ê³„ì‚°
            for issue in candidate_issues:
                issue_text = f"{issue.get('title', '')} {issue.get('body', '')[:2000]}"
                issue_tokens = self._preprocess_text(issue_text)
                
                # 1. BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
                bm25_score = self._calculate_bm25_score(question_tokens, issue_tokens, candidate_issues)
                
                # 2. ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
                semantic_score = self._calculate_semantic_score(question, issue_text)
                
                # 3. í‚¤ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°
                keyword_score = self._calculate_keyword_score(question_tokens, issue_tokens)
                
                # 4. ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
                final_score = (
                    bm25_score * 0.4 +      # BM25 ê°€ì¤‘ì¹˜ 40%
                    semantic_score * 0.4 +  # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ 40%
                    keyword_score * 0.2     # í‚¤ì›Œë“œ ë§¤ì¹­ ê°€ì¤‘ì¹˜ 20%
                )
                
                # ê° ìŠ¤ì½”ì–´ë¥¼ ì´ìŠˆì— ì €ì¥
                issue['bm25_score'] = bm25_score
                issue['semantic_score'] = semantic_score
                issue['keyword_score'] = keyword_score
                issue['final_score'] = final_score
                issue['similarity_score'] = final_score  # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
            
            # ìµœì¢… ìŠ¤ì½”ì–´ê°€ 0.2 ì´ìƒì¸ ì´ìŠˆë§Œ ë°˜í™˜
            filtered_issues = [issue for issue in candidate_issues if issue['final_score'] >= 0.2]
            
            logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ì™„ë£Œ: {len(filtered_issues)}ê°œ ì´ìŠˆê°€ ì„ê³„ê°’(0.2) ì´ìƒ")
            return filtered_issues
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            return self._fallback_similarity_calculation(question, candidate_issues)
    
    def _preprocess_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í† í°í™”, ë¶ˆìš©ì–´ ì œê±°, ì •ê·œí™”)"""
        try:
            # ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
            text = re.sub(r'[^\w\s]', ' ', text.lower())
            
            # í† í°í™”
            tokens = text.split()
            
            # ë¶ˆìš©ì–´ ì œê±° ë° ê¸¸ì´ í•„í„°ë§
            filtered_tokens = [
                token for token in tokens 
                if token not in self.stop_words and len(token) > 1
            ]
            
            return filtered_tokens
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return text.split()
    
    def _calculate_bm25_score(self, query_tokens: List[str], doc_tokens: List[str], all_docs: List[Dict[str, Any]]) -> float:
        """BM25 ìŠ¤ì½”ì–´ ê³„ì‚°"""
        try:
            if not query_tokens or not doc_tokens:
                return 0.0
            
            # BM25 íŒŒë¼ë¯¸í„°
            k1 = 1.2
            b = 0.75
            
            # ë¬¸ì„œ ê¸¸ì´
            doc_length = len(doc_tokens)
            
            # ì „ì²´ ë¬¸ì„œì˜ í‰ê·  ê¸¸ì´ ê³„ì‚°
            total_docs = len(all_docs)
            if total_docs == 0:
                return 0.0
            
            avg_doc_length = sum(len(self._preprocess_text(f"{doc.get('title', '')} {doc.get('body', '')[:2000]}")) 
                               for doc in all_docs) / total_docs
            
            # ë¬¸ì„œ ë‚´ í† í° ë¹ˆë„ ê³„ì‚°
            doc_token_counts = Counter(doc_tokens)
            
            # ì „ì²´ ë¬¸ì„œì—ì„œì˜ í† í° ë¹ˆë„ ê³„ì‚°
            all_doc_tokens = []
            for doc in all_docs:
                all_doc_tokens.extend(self._preprocess_text(f"{doc.get('title', '')} {doc.get('body', '')[:2000]}"))
            all_token_counts = Counter(all_doc_tokens)
            
            # BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
            score = 0.0
            for term in query_tokens:
                if term in doc_token_counts:
                    tf = doc_token_counts[term]
                    df = all_token_counts.get(term, 1)
                    idf = math.log((total_docs - df + 0.5) / (df + 0.5))
                    
                    # BM25 ê³µì‹
                    term_score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_length / avg_doc_length)))
                    score += term_score
            
            return score
            
        except Exception as e:
            logger.error(f"BM25 ìŠ¤ì½”ì–´ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_semantic_score(self, question: str, issue_text: str) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° (ì„ë² ë”© ê¸°ë°˜)"""
        try:
            # ì§ˆë¬¸ê³¼ ì´ìŠˆ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            question_embedding = self.embedding_model.embed_query(question)
            issue_embedding = self.embedding_model.embed_query(issue_text)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            question_array = np.array(question_embedding).reshape(1, -1)
            issue_array = np.array(issue_embedding).reshape(1, -1)
            
            similarity = cosine_similarity(question_array, issue_array)[0][0]
            return float(similarity)
            
        except Exception as e:
            logger.error(f"ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_keyword_score(self, query_tokens: List[str], doc_tokens: List[str]) -> float:
        """í‚¤ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°"""
        try:
            if not query_tokens or not doc_tokens:
                return 0.0
            
            # ê³µí†µ í† í° ì°¾ê¸°
            common_tokens = set(query_tokens) & set(doc_tokens)
            
            if not common_tokens:
                return 0.0
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            union_tokens = set(query_tokens) | set(doc_tokens)
            jaccard_score = len(common_tokens) / len(union_tokens)
            
            # ê°€ì¤‘ì¹˜ ì ìš© (ê³µí†µ í† í°ì˜ ë¹„ìœ¨)
            weighted_score = jaccard_score * (len(common_tokens) / len(query_tokens))
            
            return weighted_score
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _fallback_similarity_calculation(self, question: str, candidate_issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """LLM ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±"""
        try:
            for issue in candidate_issues:
                issue['similarity_score'] = self._calculate_similarity(question, issue.get('title', ''))
            
            # ìœ ì‚¬ë„ê°€ 0.1 ì´ìƒì¸ ì´ìŠˆë§Œ ë°˜í™˜
            filtered_issues = [issue for issue in candidate_issues if issue['similarity_score'] >= 0.1]
            
            logger.info(f"í´ë°± ë°©ì‹ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚°: {len(filtered_issues)}ê°œ ì´ìŠˆ")
            return filtered_issues
            
        except Exception as e:
            logger.error(f"í´ë°± ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return candidate_issues
    
    def _extract_search_terms(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
            cleaned = re.sub(r'[^\w\s]', ' ', question.lower())
            
            # ë¶ˆìš©ì–´ ì œê±° (ê°„ë‹¨í•œ ë²„ì „)
            stop_words = {'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì˜', 'ì™€', 'ê³¼', 'ëŠ”', 'ì€', 'ë„', 'ë§Œ', 'ë¶€í„°', 'ê¹Œì§€', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ì²˜ëŸ¼', 'ê°™ì´', 'ë³´ë‹¤', 'ë§ˆë‹¤', 'ì¡°ì°¨', 'ë§ˆì €', 'ë¿', 'ë§Œ', 'ë¿ë§Œ', 'ì•„ë‹ˆë¼', 'ë˜í•œ', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ëŸ¬ë‚˜', 'ë”°ë¼ì„œ', 'ê·¸ë˜ì„œ', 'ì™œëƒí•˜ë©´', 'ë•Œë¬¸ì—', 'ìœ„í•´', 'ìœ„í•´ì„œ', 'í†µí•´', 'í†µí•´ì„œ', 'ëŒ€í•´', 'ëŒ€í•´ì„œ', 'ê´€í•´', 'ê´€í•´ì„œ', 'ëŒ€í•œ', 'ê´€í•œ', 'ìœ„í•œ', 'í†µí•œ', 'í†µí•´', 'í†µí•´ì„œ', 'ëŒ€í•´', 'ëŒ€í•´ì„œ', 'ê´€í•´', 'ê´€í•´ì„œ', 'ëŒ€í•œ', 'ê´€í•œ', 'ìœ„í•œ', 'í†µí•œ', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ì™œ', 'ëˆ„ê°€', 'ì–´ëŠ', 'ëª‡', 'ì–¼ë§ˆë‚˜', 'ì–´ëŠ', 'ëª‡', 'ì–¼ë§ˆë‚˜', 'ì–´ëŠ', 'ëª‡', 'ì–¼ë§ˆë‚˜'}
            
            # ë‹¨ì–´ ë¶„ë¦¬ ë° ë¶ˆìš©ì–´ ì œê±°
            words = [word for word in cleaned.split() if word not in stop_words and len(word) > 1]
            
            # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ ë°˜í™˜
            return words[:5]
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return [question]
    
    def _calculate_similarity(self, question: str, title: str) -> float:
        """ì§ˆë¬¸ê³¼ ì´ìŠˆ ì œëª© ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)"""
        try:
            if not title:
                return 0.0
            
            # ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
            q_clean = re.sub(r'[^\w\s]', ' ', question.lower())
            t_clean = re.sub(r'[^\w\s]', ' ', title.lower())
            
            # ë‹¨ì–´ ë¶„ë¦¬
            q_words = set(q_clean.split())
            t_words = set(t_clean.split())
            
            if not q_words or not t_words:
                return 0.0
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            intersection = len(q_words.intersection(t_words))
            union = len(q_words.union(t_words))
            
            return intersection / union if union > 0 else 0.0
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def get_issue_answer(self, issue: Dict[str, Any]) -> Optional[str]:
        """
        Closed ì´ìŠˆì—ì„œ ë‹µë³€ ì¶”ì¶œ
        
        Args:
            issue: ì´ìŠˆ ì •ë³´
            
        Returns:
            Optional[str]: ë‹µë³€ ë‚´ìš© (ìˆë‹¤ë©´)
        """
        try:
            if issue.get('state') != 'closed':
                return None
            
            # ì´ìŠˆ ë³¸ë¬¸ì—ì„œ ë‹µë³€ ê´€ë ¨ ë‚´ìš© ì°¾ê¸°
            body = issue.get('body', '')
            if not body:
                return None
            
            # ë‹µë³€ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            answer_keywords = ['í•´ê²°', 'ë‹µë³€', 'í•´ê²°ë°©ë²•', 'í•´ê²°ì±…', 'ë°©ë²•', 'í•´ê²°ë¨', 'ìˆ˜ì •ë¨', 'ì™„ë£Œ', 'ë‹µë³€ë“œë¦½ë‹ˆë‹¤', 'í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤']
            
            has_answer = any(keyword in body for keyword in answer_keywords)
            if not has_answer:
                return None
            
            # ë‹µë³€ ë¶€ë¶„ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
            lines = body.split('\n')
            answer_lines = []
            in_answer_section = False
            
            for line in lines:
                line = line.strip()
                if any(keyword in line for keyword in answer_keywords):
                    in_answer_section = True
                
                if in_answer_section and line:
                    answer_lines.append(line)
                    
                    # ë‹µë³€ ì„¹ì…˜ì´ ëë‚˜ëŠ” ì¡°ê±´
                    if line.startswith('---') or line.startswith('##') or line.startswith('###'):
                        break
            
            if answer_lines:
                return '\n'.join(answer_lines[:10])  # ìµœëŒ€ 10ì¤„
                
            return None
            
        except Exception as e:
            logger.error(f"ì´ìŠˆ ë‹µë³€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_repository_info(self) -> Dict[str, str]:
        """Repository ì •ë³´ ë°˜í™˜"""
        return {
            'owner': self.owner,
            'repo': self.repo,
            'url': self.repository_url,
            'issues_url': f"https://github.com/{self.owner}/{self.repo}/issues"
        }


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # Issue Helper ì´ˆê¸°í™”
    issue_helper = GitHubIssueHelper()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    question = "GitHubì—ì„œ ë¬¸ì„œë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì€?"
    error_message = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # Issue ìƒì„± ì œì•ˆ
    suggestion = issue_helper.suggest_issue_creation(
        question=question,
        error_message=error_message
    )
    
    print(f"ì œì•ˆ: {suggestion['suggested']}")
    print(f"ì œëª©: {suggestion['title']}")
    print(f"URL: {suggestion['url']}")
